{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **学习目标**\n",
    "1. 张量的缩减操作\n",
    "2. 访问张量中的数据"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.1 **张量缩减操作的定义**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 张量的缩减操作是指将张量的某些维度进行压缩，减少张量中的元素数量，\n",
    "# 从而得到一个新的张量。\n",
    "# 我们所学的有关张量运算的都是在管理张量中包含的数据元素\n",
    "# 上一节学习的元素操作是在两个张量之间的元素执行操作\n",
    "# 缩减操作是对在一个张量中的元素执行操作"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.2 **第一个缩减操作**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "t = torch.tensor([\n",
    "    [0, 1, 0],\n",
    "    [2, 0, 2],\n",
    "    [0, 3, 0]\n",
    "], dtype = torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(8.)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.sum()\n",
    "# .sun()求张量中所有元素的和"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.numel()\n",
    "# .numel()求张量中元素的个数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.sum().numel()\n",
    "# 求和后再求元素数量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.sum().numel() < t.numel()\n",
    "# 比较运算，可以看出在.sum()之后得到的个数是小于原本的个数的\n",
    "# 减少了8个元素 9 - 1 =8"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.2 **结论：求和操作是一种缩减操作**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.3 **其他的常见操作**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(8.)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.prod()\n",
    "# `prod()`函数返回张量中所有元素的乘积。 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.8889)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.mean()\n",
    "# `mean()`函数的作用是计算张量中所有元素的平均值。 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.1667)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.std()\n",
    "# `std()`方法是用于计算张量中元素的标准差的函数。标准差是一种度量数据集合变化程度的指标。\n",
    "# 标准差的计算公式为：标准差 = sqrt(平均数的平方 - 平方的平均数)\n",
    "# sqrt用于计算一个数的平方根。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 以上的所有样例都将张量缩减为一个元素的张量\n",
    "# 通常，缩减操作可以用于计算张量的总和，平均值，最大值，最小值等。"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.3 **疑问：缩减操作总是会将一个张量缩减成一个元素的张量吗？**\n",
    "\n",
    "**NO！**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.4 **通常我们会在特定的轴缩减元素**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = torch.tensor([\n",
    "    [1,1,1,1],\n",
    "    [2,2,2,2],\n",
    "    [3,3,3,3]\n",
    "],dtype = torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 在特定的轴进行缩减操作，我们只需要传递轴的参数进去"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([6., 6., 6., 6.])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.sum(dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 4.,  8., 12.])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.sum(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, torch.Size([3, 4]), 2)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 这里的结果应该会有疑惑，我们结合前面的内容理解\n",
    "t.dim(), t.shape, len(t.shape)\n",
    "# t的形状和轴的数量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1., 1., 1., 1.]), tensor(1.))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 目前的 t 张量有两个轴\n",
    "# 还记得这两个输出吗\n",
    "t[0], t[0][0]\n",
    "# 第一个轴是数组，第二个轴为数字\n",
    "# sum()是元素操作的一种\n",
    "# 而元素操作\n",
    "# 两个张量必须具有相同的形状才能进行元素操作，这样才能确保元素操作中的元素位置对应"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([6., 6., 6., 6.]), tensor([6., 6., 6., 6.]))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t[0] + t[1] + t[2], t.sum(dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([True, True, True, True])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 所以 ! \n",
    "t.sum(dim=0) == t[0] + t[1] + t[2]\n",
    "# dim = 0 是第一个轴， 在 t 中第一个轴为数组 t[0] t[1] t[2]\n",
    "# 将 t.sum(dim=0) 看成是 3 个包含 4 个元素的 1 维张量元素相加\n",
    "# 形状相同才能相加，且元素操作对应\n",
    "# 6 = 1 + 2 + 3\n",
    "# 到这里我相信已经都明白了"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 同理\n",
    "# 对第二个轴进行求和"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(4.), tensor(8.), tensor(12.), tensor([ 4.,  8., 12.]))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t[0].sum(), t[1].sum(), t[2].sum(), t.sum(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([True, True, True])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.sum(dim=1) == torch.tensor([t[0].sum(), t[1].sum(), t[2].sum()])\n",
    "# 这里可以看成 4 个 包含 1 个元素的 0 维张量求和\n",
    "# 4 = 1 + 1 + 1 + 1 以此类推"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.5 **常见的缩减操作 ArgMax**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Argmax是一个数学函数：会返回一个张量中最大值的索引"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = torch.tensor([\n",
    "    [1,0,0,2],\n",
    "    [0,3,3,0],\n",
    "    [4,0,0,5]\n",
    "], dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(5.)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.max()\n",
    "# 张量中的最大值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(11)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.argmax()\n",
    "# 张量中最大值的索引\n",
    "# 这里使用的是 flatten()后的一维张量的索引"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 0., 0., 2., 0., 3., 3., 0., 4., 0., 0., 5.])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.flatten()\n",
    "# 将张量展平为一维张量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 在特定轴处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.return_types.max(\n",
       " values=tensor([4., 3., 3., 5.]),\n",
       " indices=tensor([2, 1, 1, 2])),\n",
       " torch.return_types.max(\n",
       " values=tensor([2., 3., 5.]),\n",
       " indices=tensor([3, 1, 3])))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.max(dim=0), t.max(dim=1)\n",
    "# dim=0 这个轴是数组组成的\n",
    "# 元素操作中的比较，对应位置进行比较，1 和 0 和 4 进行比较，以此类推\n",
    "# 即返回各列的最大值组成的 1 维张量\n",
    "\n",
    "# dim=1 这个轴是数字组成的\n",
    "# 元素操作中的比较，对应位置进行比较，1 和 0 和 0 和 2 进行比较，以此类推\n",
    "# 即返回各行的最大值组成的 1 维张量"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([2, 1, 1, 2]), tensor([3, 1, 3]))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.argmax(dim=0), t.argmax(dim=1)\n",
    "# dim=0返回的索引是在[0, 1, 2]之间中的一个数\n",
    "# dim=1返回的索引是在[0, 1, 2, 3]之间的一个数\n",
    "# 如果感觉理解不适， 试试理解 dim=1 是在 dim=0 的基础上的建立的\n",
    "\n",
    "# 即 dim = 0 包含\n",
    "# [ ， ， ， ，]\n",
    "# [ ， ， ， ，]\n",
    "# [ ， ， ， ，]\n",
    "# 其中每个张量包含了4个元素，进行元素操作时是 4 个一行对应位置进行比较，一行一行比较\n",
    "# 这里的一行一行，是一整行与一整行进行比较\n",
    "# 这也是为什么 dim = 0 时返回的是 4 个元素\n",
    "\n",
    "# 而 dim = 1 是\n",
    "# [1, 0, 0, 2]里面的数字1，0，0，2\n",
    "# 其中每个张量都是 0 维张量，进行元素操作时候，即 1 和 0 和 0 和 2进行元素操作\n",
    "# 也可以理解成一行一行比较，但是是在一行一行的内部进行的\n",
    "# dim=1 是在 dim=0 的基础上的建立的\n",
    "# 这样的一维张量有 3 个\n",
    "# 这也是为什么dim = 1 返回的是 3 个元素\n",
    "# 后面以此类推\n",
    "\n",
    "# dim = 0 时返回的是 4 个元素，dim = 1 返回的是 3 个元素"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用argmax函数可以沿着一个轴找到最大值的索引。\n",
    "# 它在许多应用中非常有用，例如在分类任务中找到最可能的类。\n",
    "# 在输出预测张量时使用argmax函数可以沿着一个轴找到最大值的索引。\n",
    "# 让我们确定哪个类别的预测值最高。"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.1 **访问标量张量中的值**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = torch.tensor([\n",
    "    [1,2,3],\n",
    "    [4,5,6],\n",
    "    [7,8,9]\n",
    "], dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(5.)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.mean()\n",
    "# 获得张量的均值，返回的是一个标量张量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.0"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.mean().item()\n",
    "# 转换作为数字输出，也可称访问这个标量张量中的值。\n",
    "# item()将张量中的单个值转换为Python数值并返回。\n",
    "# item()只针对！标量张量，即 0 维张量"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.2 **访问一个张量中的多个值**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([4.0, 5.0, 6.0], [2.0, 5.0, 8.0])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.mean(dim=0).tolist(), t.mean(dim=1).tolist()\n",
    "# tolist()将张量转换为Python列表的方法。\n",
    "# 这里也可以测试对dim = 0 和 dim = 1的掌握程度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1., 2., 3.]), [1.0, 2.0, 3.0])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t[0], t[0].tolist()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "d2l",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
